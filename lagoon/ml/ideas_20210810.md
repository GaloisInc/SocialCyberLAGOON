# Old Ideas from Aug 10, 2021
The goal is to predict instability events. This is essentially classification into 2 categories â€“ Unstable and Stable. Let's improve it and add a 3rd category - Highly Unstable.

## What are we trying to classify?
A good starting point would be to classify all nodes. Nodes are persons, commits, files, messages. Here's one way to do it:
- Persons
    - Unstable if a person has been inactive for a period of time T which is flanked by periods of activity on both sides. Activity is measured on the basis of commits. Even if a person makes a single commit in a month (my current time granularity is at the month level, but this can be changed), he is active. Assuming T = 12 months, a person would be inactive if he doesn't make a single commit for a continuous period of >= 12 months before and after which he was active.
    - A person can be inactive multiple times, say active from 2000-2011, inactive in 2012, active in 2013-16, inactive again in 2017-18. > 1 inactive period becomes Highly Unstable.
- Messages
    - Unstable if toxicity count is 1 (i.e. summing all the `'computed_badwords_<category>'` keys in the attributes of the message is 1).
    - Highly unstable if toxicity count is > 1.
- Commits
    - Unstable if the commit has been reverted. Note that this won't be a property of the original commit, instead a different commit will say `revert <first commit>`. In this case, both the original and the other commit which reverts the original will be considered unstable.
    - [OPTIONAL] Also unstable if the committing person has suddenly returned to activity. This can again be tracked by time stats, like say a person is inactive for a couple of periods of length T, with a single commit in between. This is quite ad-hoc though.
    - Highly unstable if a commit, along with the commit before or after it (i.e. a continuous chain of at least 2 commits) have been reverted. As before, the original set of commits as well as the new set which revert them will be considered highly unstable.
- Files
    - As of now, I haven't thought of anything for classifying files. One way could be marking files as stable / unstable / highly unstable if the commits changing them are marked the same.

## GCN approach

### How it works
Say a graph has `N` nodes and `F_0` features in each, i.e. data matrix `X_0` has shape `N x F_0` and processed adjacency matrix `A` has shape `N x N`. Each node has a ground truth label of shape `F_L` (for our 3-way case, `F_L=3`) that we are trying to predict. Imagine a L-layer neural network with layer sizes `F_1` ... `F_L`, where each has weight matrix `W_i` of shape `F_i-1 x F_i`. Compute `X_1` = act(`A` x `X_0` x `W_1`) of shape `N x F_1`, and continue doing so to get `X_L` of shape `N x F_L`. Compute the losses with the ground truth labels, backprop, and train!

Note: The quantity `A x X x W` is basically graph wts of neighboring nodes multiplied by features of this node multiplied by neural net weights. Doing this once takes the 1st hops of this node, doing it `L` times gets all hops up to a distance of `L`.

### In our case
The big challenge would be to get the feature matrix `X`. *The nodes are of different types, hence do not have similar features.* E.g. messages can have features as the length and number of bad words, but these are not applicable to persons. Moreover, if we are using number of bad words to decide the message labels (Stable / Unstable / Highly Unstable), then we should not use that as a feature since other features will become meaningless.

The alternative is focus on one (potentially suspicious) node at a time and run a GCN centered on it. But again, its adjacent nodes would all be of different types.

The bigger question really is, are GCNs the right approach? Yes the data exists as a graph, but what's preventing us from extracting graph-like features (using object properties like `obs_hops()`) and building a standard multi-layer perceptron classifier?

## Non-GCN approach(es)
We would pre-proceess the data and perform feature extraction. These would include graph features of course. The idea is that GCNs are good when we want to exploit the graph property specifically while running the ML algorithm, but that may not be necessary if we exploit the graph property to get a bunch of good features and then exploit them when running the ML algorithm. Such features could be:
- Persons
    - Number of times received abuse (i.e. toxicity count of all messages directed to this person)
    - Number of times dished out abuse
    - Average length of messages written
    - Total number of commits
    - Total number of days active
    - Average number of files changed per commit
    - Average number of lines changed per commit
    - Some density estimation features drawn from the distribution of commits
    - And of course, we usually want to avoid features that have directly led to the labels, such as number of periods of inactivity. But we can still take things like number of inactive months.
- Commits
    - Number of files changed
    - Number of lines changed
    - Number of messages which reference this commit
- Messages
    - Number of badwords of each type. This alone gives a lot of features.
    - Length of message
    - Number of other messages referenced
- Files
    - ??

One problem remains, which is each entity to b classified will have different number of features depending on what it is. So, a single one-size-fits-all classifier is not going to work (unless we find some ways to coalesce features / keep only common features / etc, but these will become highly restrictive).

Now here's the thing, since we aren't doing a GCN any more, 

## Multiple separate classifications
*We can have a separate classifier for each different type of node* (maybe excluding files, since it's hard to classify nodes of type File into Stable / Unstable / etc.). The ultimate goal is to predict instability events. These can be of various types such as a person leaving due to abuse, or a bunch of hypocrite commits, and there can be different classifiers working.

For GCNs, this can be done by filtering out nodes which are only persons, only messages, etc, and classifying them. Other nodes would not feature in the graph, but we will have to find some way to imbibe their properties in the nodes that remain.

For standard MLP classifiers, just have a separate classifier for each type of node.